2025-08-09 03:10:44,563 INFO    MainThread:82983 [wandb_setup.py:_flush():68] Current SDK version is 0.19.1
2025-08-09 03:10:44,564 INFO    MainThread:82983 [wandb_setup.py:_flush():68] Configure stats pid to 82983
2025-08-09 03:10:44,564 INFO    MainThread:82983 [wandb_setup.py:_flush():68] Loading settings from /root/.config/wandb/settings
2025-08-09 03:10:44,564 INFO    MainThread:82983 [wandb_setup.py:_flush():68] Loading settings from /data2/taoyongding/projects/LUFFY/luffy/verl/wandb/settings
2025-08-09 03:10:44,564 INFO    MainThread:82983 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-08-09 03:10:44,564 INFO    MainThread:82983 [wandb_init.py:_log_setup():528] Logging user logs to /data2/taoyongding/projects/LUFFY/luffy/verl/wandb/run-20250809_031044-kdzcttk9/logs/debug.log
2025-08-09 03:10:44,564 INFO    MainThread:82983 [wandb_init.py:_log_setup():529] Logging internal logs to /data2/taoyongding/projects/LUFFY/luffy/verl/wandb/run-20250809_031044-kdzcttk9/logs/debug-internal.log
2025-08-09 03:10:44,565 INFO    MainThread:82983 [wandb_init.py:init():644] calling init triggers
2025-08-09 03:10:44,565 INFO    MainThread:82983 [wandb_init.py:init():650] wandb.init called with sweep_config: {}
config: {'data': {'tokenizer': None, 'train_files': '/data2/taoyongding/projects/Data-Contamination-RLVR/MathMIA/MathMIA_train.parquet', 'val_files': '/data2/taoyongding/projects/LUFFY/data//valid.parquet', 'prompt_key': 'prompt', 'max_prompt_length': 1024, 'max_response_length': 3072, 'train_batch_size': 128, 'val_batch_size': 512, 'return_raw_input_ids': False, 'return_raw_chat': False, 'reward_impl_version': 3, 'filter_targets': False, 'shuffle': True, 'sample_target_ratio': 1.0, 'filter_accuracy': False, 'accuracy_lower_bound': 0.0, 'accuracy_upper_bound': 1.0, 'add_tgt_with_acc': False, 'add_tgt_acc_upper_bound': 0.5, 'disable_truncation_advantage': False}, 'actor_rollout_ref': {'hybrid_engine': True, 'model': {'path': '/data2/taoyongding/models/meta-llama-Llama-3.1-8B-Instruct', 'external_lib': None, 'override_config': {}, 'enable_gradient_checkpointing': True, 'use_remove_padding': True}, 'actor': {'strategy': 'fsdp', 'ppo_mini_batch_size': 4, 'ppo_micro_batch_size': 4, 'use_dynamic_bsz': True, 'ppo_max_token_len_per_gpu': 16384, 'grad_clip': 1.0, 'clip_ratio': 0.2, 'clip_upper_bound': 1.0, 'entropy_coeff': 0.001, 'use_kl_loss': False, 'kl_loss_coef': 0.0, 'kl_loss_type': 'low_var_kl', 'ppo_epochs': 1, 'shuffle': False, 'ulysses_sequence_parallel_size': 1, 'optim': {'lr': 1e-06, 'lr_warmup_steps_ratio': 0.0, 'min_lr_ratio': None, 'warmup_style': 'constant', 'total_training_steps': 7280}, 'fsdp_config': {'wrap_policy': {'min_num_params': 0}, 'param_offload': False, 'grad_offload': False, 'optimizer_offload': False, 'fsdp_size': -1}, 'use_sft_prefix_reward': False, 'use_sft_reward': False, 'use_off_policy_loss': True, 'off_policy_loss_impl': 'token', 'off_policy_cliprange': 0.2, 'off_policy_normalize': False, 'use_off_policy_probs': False, 'use_off_policy_clip': False, 'off_policy_max_clip': -1, 'off_policy_min_clip': -1, 'off_policy_reshape': 'no_reshape', 'off_policy_reshape_weight': 0.1, 'off_policy_reshape_pow_exp': 0.5, 'on_policy_reshape': 'no_reshape', 'on_policy_reshape_weight': 0.1, 'on_policy_reshape_pow_exp': 0.5, 'sft_prefix_reward_weight': 1.0, 'all_max_clip': -1, 'use_ppo_kl_loss': False, 'ppo_kl_loss_coef': 0.01, 'use_adaptive_temperature': False, 'use_adaptive_temperature_fixed': False, 'adaptive_temperature_clip': -1, 'adaptive_temperature_target_entropy': 1.0, 'alpha_lr': 0.01, 'debug': False, 'use_target_lst': False, 'loss_remove_token_mean': True, 'loss_remove_clip': False, 'sft_loss_coef': 1.0, 'use_sft_multitask_loss': False}, 'ref': {'fsdp_config': {'param_offload': True, 'wrap_policy': {'min_num_params': 0}}, 'log_prob_micro_batch_size': 128, 'log_prob_use_dynamic_bsz': True, 'log_prob_max_token_len_per_gpu': 16384, 'ulysses_sequence_parallel_size': 1, 'use_ref': False}, 'rollout': {'name': 'vllm', 'temperature': 1.0, 'val_temperature': 0.6, 'top_k': -1, 'top_p': 1, 'prompt_length': 1024, 'response_length': 3072, 'dtype': 'bfloat16', 'gpu_memory_utilization': 0.3, 'ignore_eos': False, 'enforce_eager': True, 'free_cache_engine': True, 'load_format': 'dummy_dtensor', 'tensor_model_parallel_size': 2, 'max_num_batched_tokens': 8192, 'max_num_seqs': 1024, 'log_prob_micro_batch_size': 128, 'log_prob_use_dynamic_bsz': True, 'log_prob_max_token_len_per_gpu': 16384, 'enable_chunked_prefill': True, 'do_sample': True, 'n': 8, 'n_val': 1, 'prefix_strategy': 'random', 'prefix_steps': 1000, 'prefix_linear_max_ratio': 0.8, 'prefix_linear_max_var': 0.1, 'max_prefix_len': 4096, 'min_prefix_ratio': 0.0, 'max_prefix_ratio': 0.0, 'prefix_reward_strategy': 'all', 'prefix_reward_weight_alpha': 1.0, 'prefix_reward_weight_beta': 1.0, 'prefix_share_across_samples': False, 'n_prefix': 1}}, 'critic': {'strategy': 'fsdp', 'optim': {'lr': 1e-05, 'lr_warmup_steps_ratio': 0.0, 'min_lr_ratio': None, 'warmup_style': 'constant', 'total_training_steps': 7280}, 'model': {'path': '~/models/deepseek-llm-7b-chat', 'tokenizer_path': '/data2/taoyongding/models/meta-llama-Llama-3.1-8B-Instruct', 'override_config': {}, 'external_lib': None, 'enable_gradient_checkpointing': True, 'use_remove_padding': False, 'fsdp_config': {'param_offload': False, 'grad_offload': False, 'optimizer_offload': False, 'wrap_policy': {'min_num_params': 0}, 'fsdp_size': -1}}, 'ppo_mini_batch_size': 4, 'ppo_micro_batch_size': 64, 'forward_micro_batch_size': 64, 'use_dynamic_bsz': True, 'ppo_max_token_len_per_gpu': 32768, 'forward_max_token_len_per_gpu': 32768, 'ulysses_sequence_parallel_size': 1, 'ppo_epochs': 1, 'shuffle': False, 'grad_clip': 1.0, 'cliprange_value': 0.5}, 'reward_model': {'enable': False, 'strategy': 'fsdp', 'model': {'input_tokenizer': '/data2/taoyongding/models/meta-llama-Llama-3.1-8B-Instruct', 'path': '~/models/FsfairX-LLaMA3-RM-v0.1', 'external_lib': None, 'use_remove_padding': False, 'fsdp_config': {'min_num_params': 0, 'param_offload': False, 'fsdp_size': -1}}, 'micro_batch_size': 64, 'max_length': None, 'ulysses_sequence_parallel_size': 1, 'use_dynamic_bsz': True, 'forward_max_token_len_per_gpu': 32768}, 'algorithm': {'gamma': 1.0, 'lam': 1.0, 'adv_estimator': 'grpo', 'kl_penalty': 'kl', 'kl_ctrl': {'type': 'fixed', 'kl_coef': 0.0}, 'grpo_use_std': False, 'surprisal_base': 0.0}, 'trainer': {'rejection_sample': False, 'rejection_sample_multiplier': 2, 'total_epochs': 20, 'total_training_steps': None, 'project_name': 'GRPO', 'experiment_name': 'Llama-3.1-8B-Instruct-MathMIA', 'logger': ['console', 'wandb'], 'nnodes': 1, 'n_gpus_per_node': 8, 'save_freq': 50, 'max_optim_to_keep': 2, 'resume_mode': 'auto', 'resume_from_path': False, 'test_freq': 10, 'critic_warmup': 0, 'default_hdfs_dir': None, 'default_local_dir': 'checkpoints/GRPO/Llama-3.1-8B-Instruct-MathMIA', 'debug': False, 'add_full_target_when_none': False, 'skip_valid_mask': False, 'acc_rebatch': False, 'skip_by_step': False, 'val_before_train': False}}
2025-08-09 03:10:44,565 INFO    MainThread:82983 [wandb_init.py:init():680] starting backend
2025-08-09 03:10:44,565 INFO    MainThread:82983 [wandb_init.py:init():684] sending inform_init request
2025-08-09 03:10:44,585 INFO    MainThread:82983 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-08-09 03:10:44,585 INFO    MainThread:82983 [wandb_init.py:init():697] backend started and connected
2025-08-09 03:10:44,591 INFO    MainThread:82983 [wandb_init.py:init():790] updated telemetry
2025-08-09 03:10:44,629 INFO    MainThread:82983 [wandb_init.py:init():822] communicating run to backend with 90.0 second timeout
2025-08-09 03:11:43,217 INFO    Thread-1 (wrapped_target):82983 [retry.py:__call__():172] Retry attempt failed:
Traceback (most recent call last):
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/connectionpool.py", line 773, in urlopen
    self._prepare_proxy(conn)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1042, in _prepare_proxy
    conn.connect()
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/connection.py", line 721, in connect
    self._tunnel()
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/connection.py", line 255, in _tunnel
    (version, code, message) = response._read_status()  # type: ignore[attr-defined]
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/http/client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/socket.py", line 717, in readinto
    return self._sock.recv_into(b)
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/connectionpool.py", line 775, in urlopen
    self._raise_timeout(
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/urllib3/connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/wandb/sdk/lib/retry.py", line 131, in __call__
    result = self._call_fn(*args, **kwargs)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 393, in execute
    return self.client.execute(*args, **kwargs)  # type: ignore
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 52, in execute
    result = self._get_result(document, *args, **kwargs)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 60, in _get_result
    return self.transport.execute(document, *args, **kwargs)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/wandb/sdk/lib/gql_request.py", line 58, in execute
    request = self.session.post(self.url, **post_args)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Read timed out. (read timeout=20)
2025-08-09 03:12:14,689 ERROR   MainThread:82983 [wandb_init.py:init():849] encountered error: Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`.
2025-08-09 03:12:14,690 ERROR   MainThread:82983 [wandb_init.py:init():1308] error in wandb.init()
Traceback (most recent call last):
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1298, in init
    return wi.init()
  File "/data2/taoyongding/miniconda3/envs/luffy/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 855, in init
    raise error
wandb.errors.errors.CommError: Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`.
