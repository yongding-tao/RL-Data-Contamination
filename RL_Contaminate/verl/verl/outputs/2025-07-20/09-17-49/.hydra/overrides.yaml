- algorithm.adv_estimator=grpo
- data.train_files=/data2/taoyongding/projects/LUFFY/data//openr1.parquet
- data.val_files=/data2/taoyongding/projects/LUFFY/data//valid.parquet
- data.train_batch_size=16
- data.val_batch_size=64
- data.max_prompt_length=1024
- data.max_response_length=2048
- actor_rollout_ref.model.path=/data2/taoyongding/models/meta-llama-Llama-3.1-8B-Instruct
- actor_rollout_ref.actor.optim.lr=1e-6
- actor_rollout_ref.model.use_remove_padding=True
- actor_rollout_ref.actor.ppo_mini_batch_size=4
- actor_rollout_ref.actor.ppo_micro_batch_size=4
- actor_rollout_ref.actor.use_dynamic_bsz=True
- actor_rollout_ref.actor.ppo_max_token_len_per_gpu=32768
- actor_rollout_ref.actor.kl_loss_coef=0.00
- actor_rollout_ref.actor.kl_loss_type=low_var_kl
- actor_rollout_ref.actor.ulysses_sequence_parallel_size=1
- actor_rollout_ref.model.enable_gradient_checkpointing=True
- actor_rollout_ref.actor.fsdp_config.param_offload=False
- actor_rollout_ref.actor.fsdp_config.grad_offload=False
- actor_rollout_ref.actor.fsdp_config.optimizer_offload=False
- actor_rollout_ref.rollout.tensor_model_parallel_size=4
- actor_rollout_ref.rollout.name=vllm
- actor_rollout_ref.rollout.temperature=1.0
- actor_rollout_ref.rollout.val_temperature=0.6
- actor_rollout_ref.rollout.gpu_memory_utilization=0.30
- actor_rollout_ref.rollout.n=8
- actor_rollout_ref.rollout.n_val=1
- actor_rollout_ref.ref.fsdp_config.param_offload=True
- actor_rollout_ref.rollout.max_prefix_len=4096
- algorithm.kl_ctrl.kl_coef=0.000
- actor_rollout_ref.actor.entropy_coeff=0.001
- trainer.critic_warmup=0
- trainer.logger=['console']
- trainer.project_name=GRPO
- trainer.experiment_name=Llama-3.1-8B-Instruct
- +trainer.val_before_train=False
- trainer.n_gpus_per_node=8
- trainer.nnodes=1
- trainer.save_freq=1000
- trainer.test_freq=100
- actor_rollout_ref.actor.use_kl_loss=False
- actor_rollout_ref.actor.use_sft_prefix_reward=False
- actor_rollout_ref.rollout.prefix_share_across_samples=False
- actor_rollout_ref.rollout.prefix_strategy=random
- actor_rollout_ref.rollout.n_prefix=1
- actor_rollout_ref.rollout.min_prefix_ratio=0.0
- actor_rollout_ref.rollout.max_prefix_ratio=0.0
- actor_rollout_ref.rollout.prefix_reward_weight_alpha=1.0
- actor_rollout_ref.ref.use_ref=False
- actor_rollout_ref.actor.use_off_policy_loss=True
- actor_rollout_ref.actor.off_policy_normalize=False
- actor_rollout_ref.actor.off_policy_loss_impl=token
- algorithm.grpo_use_std=False
- actor_rollout_ref.actor.loss_remove_token_mean=True
- data.reward_impl_version=3
- trainer.max_optim_to_keep=2
- data.shuffle=True
- trainer.default_hdfs_dir=null
- trainer.total_epochs=1
